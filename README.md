# AI-Generated Image Detector: A Flask-Based Web App with CI/CD on Azure for Real vs Synthetic Image Classification
![real versus fake](real-vs-fake-image.png)
This repository contains an end-to-end application for detecting whether an image is real or has been generated by AI. The application is powered by a convolutional neural network (CNN) model built with transfer learning, integrated with experiment tracking, and deployed using modern DevOps practices. Below is an overview of the project and instructions for use.

---
## Table of Contents
- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Directory Structure](#directory-structure)
- [Key Features](#features)
- [Tools and Technologies](#technologies-used)
- [Pipeline Stages](#pipeline-stages)
- [Setup and Installation](#setup-and-installation)
- [AWS Deployment](#deployment)
- [Usage](#usage)
- [Future Work](#future-work)
- [Contributing](#contributing)
- [License](#license)

## Project Overview
The Real vs AI-Generated Image Classification app has diverse use cases across industries. In media and journalism, it can help verify the authenticity of images, ensuring accurate reporting and mitigating the spread of misinformation. In cybersecurity, it can detect AI-generated images used in phishing attacks, deepfakes, or identity fraud. Social media platforms can integrate the app to flag AI-generated content, enhancing transparency and promoting ethical content sharing. Researchers and educators can use it to study advancements in AI-generated media and teach concepts related to image classification and transfer learning. Additionally, businesses and organizations can employ the app to maintain brand integrity by identifying unauthorized use of AI-generated visuals in marketing or advertising campaigns.

This project is designed to classify images as either real or AI-generated. The solution leverages a pre-trained VGG16 model from ImageNet, updated with custom layers for binary classification. The application implements a robust pipeline for data ingestion, model development, training, evaluation, and deployment.

The project architecture includes:
1. **Data Ingestion**: Real and AI-generated images are fetched from an S3 bucket.
2. **Model Development**: Transfer learning on VGG16 with custom layers for binary classification.
3. **Pipeline Stages**: Managed using DVC to ensure reproducibility.
4. **Experiment Tracking**: MLflow and Dagshub used to log metrics and track experiments.
5. **Web App Deployment**: Flask app containerized with Docker, deployed using Azure Web App Service and GitHub Actions.

## Dataset
The dataset used for training and evaluating the model was sourced from [Kaggle](https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images). It comprises 120,000 images, evenly split between 60,000 real images (from CIFAR-10) and 60,000 synthetically generated images. To streamline storage and retrieval, the dataset was compressed and uploaded to an AWS S3 bucket, from where it was accessed during the pipeline for model training and evaluation. The dataset is organized into train and test directories, each containing two subfolders: REAL and FAKE. These subfolders house images specific to their respective categories, providing a clear and efficient structure for training and validating the model. This organization ensures seamless integration into the data pipeline and facilitates robust model development.

## Directory Structure

```
.
├── .github/                  
│   └── workflows/
│       └── main_imageauth.yml
├── artifacts/
│   ├── data_ingestion/
│   ├── prepare_base_model/
│   └── training/
├── config/
│   └── config.yaml
├── log/
│   └── running_logs.log        
├── research/
│   ├── 01_data_ingestion.ipynb
│   ├── 02_prepare_base_model.ipynb
│   ├── 03_model_trainer.ipynb
│   ├── 04_model_evaluation_with_mlflow.ipynb
│   └── 05_prediction.ipynb
├── src/                  
│   └── image_authenticity_detector/
│       ├── components/
│       ├── config/
│       ├── constants/
│       ├── entity/
│       ├── pipeline/
│       └── utils
├── templates/                        # HTML templates               
│   └── index.html
├── app.py                            # Main Flask application
├── Dockefile                         # Docker configuration file    
├── dvc.yaml                          # DVC pipeline stages
├── main.py            
├── params.yaml              
├── README.md                         # Project documentation
├── requirements.txt                  # Python dependencies
├── scores.json      
├── pyproject.toml             
└── template.py             
```
## Key Features

- **Transfer Learning**: Utilizes the VGG16 model pre-trained on ImageNet with customized top layers.
- **Experiment Tracking**: Integrated with MLflow and Dagshub for deep learning experiment tracking and model management.
- **Pipeline Automation**: Implements DVC for managing pipeline stages, including data ingestion, model training, and evaluation.
- **Web Application**: Flask-based web interface for image classification.
- **CI/CD Workflow**: Automated deployment using Docker, Azure Web App Service, Azure Container Registry (ACR), and GitHub Actions.

## Tools and Technologies

- **Programming Language**: Python
- **Machine Learning**: TensorFlow, Keras, CNN, Transfer Learning
- **Pipeline Management**: DVC
- **Experiment Tracking**: MLflow, Dagshub
- **Web Framework**: Flask
- **Cloud Services**: S3, Azure Web App Service, Azure Container Registry
- **Version Control & CI/CD**: Git, GitHub Actions
- **Containerisation**: Docker

## Pipeline Stages
- **Data Ingestion**: Fetch images from the S3 bucket and prepare the dataset.
- **Base Model Development**: Modify the VGG16 model for binary classification.
- **Model Training**: Train the updated model using real and AI-generated images.
- **Model Evaluation**: Evaluate the model's performance on the validation set.

